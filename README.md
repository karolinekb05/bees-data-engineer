### EN-US

# Brewery Data Pipeline - BEES Case ğŸ»

This project is a data pipeline solution designed to consume data from the **Open Brewery DB API**, transforming and persisting it into a data lake following the **Medallion Architecture** (Bronze, Silver, and Gold layers).

## ğŸ—ï¸ Data Lake Architecture
The project implements three distinct layers to ensure data integrity and analytical readiness:

* **Bronze (Raw):** Persists raw data from the API in its native format (JSON) using PySpark.
* **Silver (Curated):** Cleans and normalizes data into a columnar format (**Parquet**), partitioned by brewery location (country/state).
* **Gold (Analytical):** Provides an aggregated view showing the **quantity of breweries per type and location**.

---

## ğŸ› ï¸ Tech Stack and Design Choices
* **Orchestration:** **Apache Airflow** â€“ Selected for its robust handling of scheduling, retries, and error handling.
* **Language:** **Python/PySpark** â€“ Chosen for efficient data transformation and scalability.
* **Containerization:** **Docker & Docker Compose** â€“ Used for modularization and environment consistency.

---

## ğŸš€ How to Run the Project

### Prerequisites
* Docker and Docker Compose installed.

### Step-by-Step Instructions
1.  **Build and start the environment:**
    ```bash
    docker-compose up --build
    ```
2.  **Access the Airflow UI:**
    * URL: `http://localhost:8080`

3.  **Activate the Pipeline:**
    * Locate the `bees_brewery` DAG and toggle it to start the sequential execution of the medallion layers.

---

## ğŸ›¡ï¸ Error Handling and Monitoring
As per the case requirements, the pipeline includes:

* **Retries:** Ingestion tasks include automatic retry policies for API stability.
* **Data Quality:** The Silver layer validates mandatory fields and data types before proceeding to Gold.
* **Monitoring/Alerting:** In a production environment, an `on_failure_callback` would trigger alerts (Slack/Email) for pipeline failures or data quality issues.

---

## â˜ï¸ Cloud Considerations
If deployed to a cloud environment (AWS/GCP):
* Local storage is replaced by **S3** or **GCS**.
* Credentials must be managed via **Airflow Connections** or **Secrets Manager**.

---

### PT-BR

# Brewery Data Pipeline - BEES Case ğŸ»
Pipeline de dados seguindo a Arquitetura Medallion (Bronze â†’ Silver â†’ Gold) para consumo da API Open Brewery DB, focado em escalabilidade, particionamento eficiente e qualidade de dados.

## ğŸ—ï¸ Arquitetura do Data Lake
O projeto implementa trÃªs camadas distintas para garantir a integridade dos dados:

**Bronze (Raw)**: IngestÃ£o dos dados em seu formato nativo (JSON) para garantir a persistÃªncia da fonte original sem perdas com PySpark.

**Silver (Curated)**: Limpeza e normalizaÃ§Ã£o dos dados. O armazenamento Ã© feito em Parquet (colunar) com particionamento por localizaÃ§Ã£o (paÃ­s/estado) para otimizaÃ§Ã£o de consultas.

**Gold (Analytical)**: Camada agregada que fornece a quantidade de cervejarias por tipo e localizaÃ§Ã£o, pronta para consumo por ferramentas de BI.


## ğŸ› ï¸ Stack TecnolÃ³gica e DecisÃµes

**OrquestraÃ§Ã£o**: Apache Airflow â€“ escolhido pela robustez no gerenciamento de agendamento, retentativas (retries) e tratamento de falhas.

**Linguagem**: Python/PySpark â€“ preferÃªncia tÃ©cnica para manipulaÃ§Ã£o eficiente de grandes volumes de dados e transformaÃ§Ãµes complexas.

**ContainerizaÃ§Ã£o**: Docker & Docker Compose â€“ garantem a modularizaÃ§Ã£o e reprodutibilidade do ambiente de execuÃ§Ã£o.

## ğŸš€ Como Executar o Projeto

**PrÃ©-requisitos**
Docker e Docker Compose instalados.

**Passo a Passo**
1. Construir e subir o ambiente:

    ```bash
    docker-compose up --build
    ```

2. Acessar o Airflow:

URL: `http://localhost:8080`(Login/Senha padrÃ£o definidos no compose).

3. Ativar o Pipeline:

Localize a DAG `bees_brewery` e ative-a para iniciar a execuÃ§Ã£o sequencial das camadas.

## ğŸ›¡ï¸ Tratamento de Erros e Monitoramento
Conforme exigido pelo caso, o pipeline inclui:

**Retries**: As tasks de ingestÃ£o possuem polÃ­tica de retentativa automÃ¡tica em caso de falha na API.

**Data Quality Checks**: A camada Silver valida campos obrigatÃ³rios e tipos de dados antes de prosseguir para a Gold. Se um check falhar, o pipeline Ã© interrompido para evitar poluiÃ§Ã£o da camada analÃ­tica.

**Alertas Sugeridos**: Em um ambiente produtivo (Cloud), seria implementado o envio de alertas via Slack/E-mail atravÃ©s de on_failure_callback no Airflow.

## â˜ï¸ ConsideraÃ§Ãµes de Cloud
Caso o deploy seja realizado em nuvem (AWS/GCP/Azure):

O armazenamento local seria substituÃ­do por S3 ou GCS.

As chaves de acesso devem ser configuradas via Airflow Connections ou Secrets Manager, nunca expostas no repositÃ³rio.